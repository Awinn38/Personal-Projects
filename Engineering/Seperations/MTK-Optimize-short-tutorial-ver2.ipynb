{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#  In this mini-tutorial, several optimization problems are solved \r\n",
    "#  using the ModelingToolkit.jl and GalacticOptim.jl packages in Julia. \r\n",
    "\r\n",
    "#  The function to be optimized (minimized) is the Rosenbrock function:\r\n",
    "\r\n",
    "#       (1 - x)^2 + 100 * (y - x^2)^2\r\n",
    "\r\n",
    "#  The above function is a common test function for optimization methods. \r\n",
    "#  By inspection, it can be see that the minimum is at x = y = 1 \r\n",
    "#  and the function value is zero at this location.  Despite having an\r\n",
    "#  obvious solution, this problem is still a useful numerical test case.\r\n",
    "\r\n",
    "#  The packages ModelingToolkit.jl, GlacticOptim.jl, and Optim.jl\r\n",
    "#  need to be installed for this tutorial.\r\n",
    "\r\n",
    "#  Date:  9/8/2021\r\n",
    "\r\n",
    "#  Author:  Doug Frey, UMBC\r\n",
    "\r\n",
    "#  Julia version 1.6.1 was used to create this tutorial"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#  The following package versions were used \r\n",
    "#  for this tutorial:\r\n",
    "\r\n",
    "#\r\n",
    "#      Status `C:\\Users\\Douglas Frey\\environment_v161_var1\\Project.toml`\r\n",
    "#   [a75be94c] GalacticOptim v2.0.3\r\n",
    "#   [961ee093] ModelingToolkit v6.4.9\r\n",
    "#   [429524aa] Optim v1.4.1\r\n",
    "#   [1dea7af3] OrdinaryDiffEq v5.55.1\r\n",
    "#   [91a5bcdd] Plots v1.21.3\r\n",
    "\r\n",
    "#  Package versions can be checked by running the following commands.\r\n",
    "\r\n",
    "#  First import Pkg:\r\n",
    "\r\n",
    "       import Pkg\r\n",
    "\r\n",
    "#  The command below is only needed if Julia 1.6.1 is being used in\r\n",
    "#  a Jupyter notebook due to a bug in Julia 1.6.1. This command can\r\n",
    "#  be deleted otherwise.\r\n",
    "\r\n",
    "       Pkg.DEFAULT_IO[] = stdout\r\n",
    "\r\n",
    "#  Write the status to the output:\r\n",
    "\r\n",
    "       Pkg.status()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[32m\u001b[1m      Status\u001b[22m\u001b[39m `C:\\Users\\Douglas Frey\\environment_v161_var1\\Project.toml`\n",
      " \u001b[90m [a75be94c] \u001b[39m\u001b[37mGalacticOptim v2.0.3\u001b[39m\n",
      " \u001b[90m [961ee093] \u001b[39m\u001b[37mModelingToolkit v6.4.9\u001b[39m\n",
      " \u001b[90m [429524aa] \u001b[39m\u001b[37mOptim v1.4.1\u001b[39m\n",
      " \u001b[90m [1dea7af3] \u001b[39m\u001b[37mOrdinaryDiffEq v5.55.1\u001b[39m\n",
      " \u001b[90m [91a5bcdd] \u001b[39m\u001b[37mPlots v1.21.3\u001b[39m\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#  Make available for use the needed packages:\r\n",
    "\r\n",
    "using ModelingToolkit, GalacticOptim, Optim"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "#  Example problem 1 where the Rosenbrock function\r\n",
    "#  is minimized with no constraints\r\n",
    "\r\n",
    "#   Newton Trust Region method will  be used\r\n",
    "\r\n",
    "#  Define the variables and parameters.\r\n",
    "\r\n",
    "@variables x y \r\n",
    "@parameters a b\r\n",
    "\r\n",
    "#  Define the objective function\r\n",
    "\r\n",
    "objective = (a - x)^2 + b * (y - x^2)^2\r\n",
    "\r\n",
    "#  Create an OptmizationSystem object and name it\r\n",
    "\r\n",
    "@named  sys = OptimizationSystem(objective, [x,y], [a,b])\r\n",
    "\r\n",
    "#  Set initial guess.  Note that on purpose a very bad \r\n",
    "#  initial guess will be used.\r\n",
    "\r\n",
    "u0 = [ x => -1.0, y => -2.0]\r\n",
    "\r\n",
    "#  Set parameters\r\n",
    "\r\n",
    "params = [ a => 1.0, b => 100.0]\r\n",
    "\r\n",
    "#  Define the problem to solve.  Note that the Newton Trust\r\n",
    "#  Region method needs both the gradient and  Hessian matrix.\r\n",
    "#  These will be determined by automatic differentiation (not\r\n",
    "#  finite differences).\r\n",
    "\r\n",
    "prob = OptimizationProblem(sys,u0, params, grad=true, hess=true)\r\n",
    "\r\n",
    "#  Create a callback function to monitor the progress to convergence\r\n",
    "\r\n",
    "callback = function (p,l)\r\n",
    "    println(\"Objective function value =  $l\")\r\n",
    "    return false\r\n",
    "end\r\n",
    "\r\n",
    "#  Use the Newton Trust Region method. Desired error is 10^-12. A maximum\r\n",
    "#  of 100 iterations will be performed with objective function value \r\n",
    "#  reported every 5 iterations.  Maximum time limit is 100 seconds:\r\n",
    "\r\n",
    "result = solve(prob, NewtonTrustRegion(),x_abstol = 1e-12, \r\n",
    "                   f_abstol = 1e-12, g_abstol = 1e-12, cb = callback, \r\n",
    "                    show_every = 5, time_limit = 100 , iterations=100)\r\n",
    "\r\n",
    "println(\" \")\r\n",
    "println(\"Final value of objective function = \", result.minimum)\r\n",
    "println(\" \")\r\n",
    "println(\"Final value for x = \", result.minimizer[1])\r\n",
    "println(\" \")\r\n",
    "println(\"Final value for y = \", result.minimizer[2])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Objective function value =  -88.88888888888894\n",
      "Objective function value =  480.3278688524589\n",
      "Objective function value =  6493.2223543400305\n",
      "Objective function value =  102494.16710456138\n",
      "Objective function value =  1.6384942267850186e6\n",
      "Objective function value =  2.621449422984221e7\n",
      "Objective function value =  4.194304940571426e8\n",
      "Objective function value =  6.710886449786324e9\n",
      "Objective function value =  1.0737417111645421e11\n",
      "Objective function value =  1.7179840057880579e12\n",
      "Objective function value =  2.7487045060676395e13\n",
      " \n",
      "Final value of objective function = -6.601367531975355e14\n",
      " \n",
      "Final value for x = 3.6000000000001364\n",
      " \n"
     ]
    },
    {
     "output_type": "error",
     "ename": "LoadError",
     "evalue": "BoundsError: attempt to access 1-element Vector{Float64} at index [2]",
     "traceback": [
      "BoundsError: attempt to access 1-element Vector{Float64} at index [2]",
      "",
      "Stacktrace:",
      " [1] getindex(A::Vector{Float64}, i1::Int64)",
      "   @ Base .\\array.jl:801",
      " [2] top-level scope",
      "   @ In[22]:55",
      " [3] eval",
      "   @ .\\boot.jl:360 [inlined]",
      " [4] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1116"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#  Now take a look at some results symbolically\r\n",
    "#  to show symbolics ability of ModelingToolkit.jl\r\n",
    "\r\n",
    "#  First show the gradient\r\n",
    "\r\n",
    "Symbolics.gradient(objective,[x,y])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/latex": [
       "\\begin{equation}\n",
       "\\left[\n",
       "\\begin{array}{c}\n",
       " - 2 a + 2 x - 2 b x \\left( 2 y - 2 x^{2} \\right) \\\\\n",
       "b \\left( 2 y - 2 x^{2} \\right) \\\\\n",
       "\\end{array}\n",
       "\\right]\n",
       "\\end{equation}\n"
      ],
      "text/plain": [
       "2-element Vector{Num}:\n",
       " 2x - (2a) - (2b*x*(2y - (2(x^2))))\n",
       "                  b*(2y - (2(x^2)))"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#  Next show the Hessian matrix symbolically\r\n",
    "\r\n",
    "Symbolics.hessian(objective,[x,y])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/latex": [
       "\\begin{equation}\n",
       "\\left[\n",
       "\\begin{array}{cc}\n",
       "2 + 8 x^{2} b - 2 b \\left( 2 y - 2 x^{2} \\right) &  - 4 b x \\\\\n",
       " - 4 b x & 2 b \\\\\n",
       "\\end{array}\n",
       "\\right]\n",
       "\\end{equation}\n"
      ],
      "text/plain": [
       "2Ã—2 Matrix{Num}:\n",
       " 2 + 8b*(x^2) - (2b*(2y - (2(x^2))))  -4b*x\n",
       "                               -4b*x     2b"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#  Next show d(objective_function)/dx symbolically\r\n",
    "\r\n",
    "Dx = Differential(x)\r\n",
    "\r\n",
    "expand_derivatives(Dx(objective))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/latex": [
       "\\begin{equation}\n",
       " - 2 a + 2 x - 2 b x \\left( 2 y - 2 x^{2} \\right)\n",
       "\\end{equation}\n"
      ],
      "text/plain": [
       "2x - (2a) - (2b*x*(2y - (2(x^2))))"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#  Example problem 2 where the Rosenbrock function\r\n",
    "#  is minimized with no constraints\r\n",
    "\r\n",
    "#   The Broyden, Fletcher, Golfarb, Shanno (BFGS) Quasi-Newton\r\n",
    "#   method will be used\r\n",
    "\r\n",
    "#  Define the variables and parameters.\r\n",
    "\r\n",
    "@variables x y \r\n",
    "@parameters a b\r\n",
    "\r\n",
    "#  Define the objective function\r\n",
    "\r\n",
    "objective = (a - x)^2 + b * (y - x^2)^2\r\n",
    "\r\n",
    "#  Create an OptmizationSystem object and name it\r\n",
    "\r\n",
    "@named  sys = OptimizationSystem(objective, [x,y], [a,b])\r\n",
    "\r\n",
    "#  Set initial guess.  Note that on purpose a very bad \r\n",
    "#  initial guess will be used.\r\n",
    "\r\n",
    "u0 = [ x => -1.0, y=>-2.0]\r\n",
    "\r\n",
    "#  Set parameters\r\n",
    "\r\n",
    "params = [ a => 1.0, b => 100.0]\r\n",
    "\r\n",
    "#  Define the problem to solve.  Note that the BFGS method \r\n",
    "#  needs only the gradient to be supplied (not the Hessian matrix)\r\n",
    "#  since the latter is approximated internally by the method.\r\n",
    "\r\n",
    "prob = OptimizationProblem(sys,u0, params, grad=true, hess=false)\r\n",
    "\r\n",
    "#  Create a callback function to monitor the progress to convergence\r\n",
    "\r\n",
    "callback = function (p,l)\r\n",
    "    println(\"Objective function value =  $l\")\r\n",
    "    return false\r\n",
    "end\r\n",
    "\r\n",
    "#  Use the BFGS method. Desired error is 10^-12. A maximum\r\n",
    "#  of 100 iterations will be performed with objective function value \r\n",
    "#  reported every 5 iterations.  Maximum time limit is 100 seconds:\r\n",
    "\r\n",
    "result = solve(prob, BFGS(),x_abstol = 1e-12, \r\n",
    "                   f_abstol = 1e-12, g_abstol = 1e-12, cb = callback, \r\n",
    "                    show_every = 5, time_limit = 100 , iterations=100)\r\n",
    "\r\n",
    "println(\" \")\r\n",
    "println(\"Final value of objective function = \", result.minimum)\r\n",
    "println(\" \")\r\n",
    "println(\"Final value for x = \", result.minimizer[1])\r\n",
    "println(\" \")\r\n",
    "println(\"Final value for y = \", result.minimizer[2])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Objective function value =  904.0\n",
      "Objective function value =  2.741686784696231\n",
      "Objective function value =  0.7183143047436891\n",
      "Objective function value =  0.19150437378083918\n",
      "Objective function value =  0.01045448959359955\n",
      "Objective function value =  3.0853818626490574e-5\n",
      " \n",
      "Final value of objective function = 1.5407439555097887e-30\n",
      " \n",
      "Final value for x = 0.9999999999999994\n",
      " \n",
      "Final value for y = 0.9999999999999988\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "#  Example problem 3 where the Rosenbrock function\r\n",
    "#  is optimized with no constraints\r\n",
    "\r\n",
    "#  The Nelder-Mead method will be used. Note this method\r\n",
    "#  does not use either the gradient or Hessian and only\r\n",
    "#  uses function evaluations.\r\n",
    "\r\n",
    "#  Define the variables and parameters.\r\n",
    "\r\n",
    "@variables x y \r\n",
    "@parameters a b\r\n",
    "\r\n",
    "#  Remainder of statements are similar to the first two examples\r\n",
    "#  so most comments are eliminated below.\r\n",
    "\r\n",
    "objective = (a - x)^2 + b * (y - x^2)^2\r\n",
    "\r\n",
    "@named  sys = OptimizationSystem(objective, [x,y], [a,b])\r\n",
    "\r\n",
    "u0 = [ x => -1.0, y=>-2.0]\r\n",
    "\r\n",
    "params = [ a => 1.0, b => 100.0]\r\n",
    "\r\n",
    "#  The Nelder-Mead method does not need either the gradient or\r\n",
    "#  Hessian matrix.  Only function evaluations are used.\r\n",
    "\r\n",
    "prob = OptimizationProblem(sys,u0, params, grad=false, hess=false)\r\n",
    "\r\n",
    "callback = function (p,l)\r\n",
    "    println(\"Objective function value =  $l\")\r\n",
    "    return false\r\n",
    "end\r\n",
    "\r\n",
    "#  The Nelder Mead method will be used.  Since this method is less\r\n",
    "#  efficient per iteration, more iterations are needed than before.\r\n",
    "\r\n",
    "result = solve(prob, NelderMead(),x_abstol = 1e-12, \r\n",
    "                   f_abstol = 1e-12, g_abstol = 1e-12, cb = callback, \r\n",
    "                    show_every = 20, time_limit = 100 , iterations=200)\r\n",
    "\r\n",
    "println(\" \")\r\n",
    "println(\"Final value of objective function = \", result.minimum)\r\n",
    "println(\" \")\r\n",
    "println(\"Final value for x = \", result.minimizer[1])\r\n",
    "println(\" \")\r\n",
    "println(\"Final value for y = \", result.minimizer[2])\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Objective function value =  1584.0625\n",
      "Objective function value =  1.1631774358416251\n",
      "Objective function value =  0.29180164434997524\n",
      "Objective function value =  0.04497657891310023\n",
      "Objective function value =  4.900320352970663e-5\n",
      "Objective function value =  1.387365135275737e-10\n",
      " \n",
      "Final value of objective function = 8.195450959885444e-14\n",
      " \n",
      "Final value for x = 1.0000001196491832\n",
      " \n",
      "Final value for y = 1.0000002653057993\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "#  Example problem 4 where the Rosenbrock function\r\n",
    "#  is optimized with upper and lower limits on the\r\n",
    "#  search variables.\r\n",
    "\r\n",
    "#  The Particle Swarm method will be used. Note this method\r\n",
    "#  does not use either the gradient or Hessian and only\r\n",
    "#  uses function evaluations. The method permits upper and\r\n",
    "#  lower limits on the search variables which may be useful.\r\n",
    "#  Particle Swarm method a global optimization and not a\r\n",
    "#  local optimization like the other options shown above.\r\n",
    "\r\n",
    "#  Define the variables and parameters.\r\n",
    "\r\n",
    "@variables x y \r\n",
    "@parameters a b\r\n",
    "\r\n",
    "#  Remainder of statements are similar to the first two examples\r\n",
    "#  so most comments are eliminated below.\r\n",
    "\r\n",
    "objective = (a - x)^2 + b * (y - x^2)^2\r\n",
    "\r\n",
    "@named  sys = OptimizationSystem(objective, [x,y], [a,b])\r\n",
    "\r\n",
    "u0 = [ x => -1.0, y=>-1.0]\r\n",
    "\r\n",
    "params = [ a => 1.0, b => 100.0]\r\n",
    "\r\n",
    "#  Niether gradient nor Hessian are needed\r\n",
    "\r\n",
    "prob = OptimizationProblem(sys, u0, params, grad=false, hess=false)\r\n",
    "\r\n",
    "callback = function (p,l)\r\n",
    "    println(\"Objective function value =  $l\")\r\n",
    "    return false\r\n",
    "end\r\n",
    "\r\n",
    "#  Define upper and lower limits for x and y.  First\r\n",
    "#  element in the two vectors below corresponds to x and\r\n",
    "#  the second element corresponds to y.\r\n",
    "\r\n",
    "lower_limit = [0.0, 0.0]\r\n",
    "\r\n",
    "upper_limit = [0.5, 0.5]\r\n",
    "\r\n",
    "#  Particle Swarm method may needs lots of iterations.  100 search\r\n",
    "#  particles will be used here.\r\n",
    "\r\n",
    "         result = GalacticOptim.solve(prob, \r\n",
    "                Optim.ParticleSwarm(lower = lower_limit, upper = upper_limit, \r\n",
    "                   n_particles = 100), x_abstol = 1e-12, f_abstol = 1e-12, \r\n",
    "                      g_abstol = 1e-12, cb = callback, \r\n",
    "                      show_every = 10, time_limit = 600, iterations=100);\r\n",
    "\r\n",
    "#  Note that due to the constraints the x=y=1 minimimum cannot be achieved.\r\n",
    "\r\n",
    "println(\" \")\r\n",
    "println(\"Final value of objective function = \", result.minimum)\r\n",
    "println(\" \")\r\n",
    "println(\"Final value for x = \", result.minimizer[1])\r\n",
    "println(\" \")\r\n",
    "println(\"Final value for y = \", result.minimizer[2])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Objective function value =  4.672545911606741\n",
      "Objective function value =  0.7571318506576622\n",
      "Objective function value =  0.2572178731228865\n",
      "Objective function value =  0.25021454245109676\n",
      "Objective function value =  0.25000000221498797\n",
      "Objective function value =  0.2500000007252524\n",
      "Objective function value =  0.25000000000373196\n",
      "Objective function value =  0.2500000000000003\n",
      "Objective function value =  0.25\n",
      "Objective function value =  0.25\n",
      "Objective function value =  0.25\n",
      " \n",
      "Final value of objective function = 0.25\n",
      " \n",
      "Final value for x = 0.5\n",
      " \n",
      "Final value for y = 0.2500000004420881\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "#  Example problem 5 where the Rosenbrock function\r\n",
    "#  is optimized.  An equality constraint on x and y\r\n",
    "#  will be used. The problem solved is:\r\n",
    "\r\n",
    "#       minimize:   (1 - x)^2 + 100 * (y - x^2)^2\r\n",
    "#       subject to:     x*y = 2.0\r\n",
    "\r\n",
    "#  Using the concept of a penalty function, the above problem\r\n",
    "#  can be solved as follows:\r\n",
    "\r\n",
    "#    minimize (1-x)^2 + 100*(y-x^2)^2 + penalty_factor*(x*y-2.0)^2\r\n",
    "#       where  penalty_factor is a large number (e.g., 10^6)\r\n",
    "\r\n",
    "#  The BFGS method will be used. \r\n",
    "\r\n",
    "#  Define the variables and parameters.\r\n",
    "\r\n",
    "@variables x y \r\n",
    "@parameters a b penalty_factor\r\n",
    "\r\n",
    "#  Remainder of statements are similar to the first two examples\r\n",
    "#  so most comments are eliminated below.\r\n",
    "\r\n",
    "objective = (a - x)^2 + b * (y - x^2)^2  + penalty_factor*(x*y-2.0)^2\r\n",
    "\r\n",
    "@named  sys = OptimizationSystem(objective, [x,y], [a,b,penalty_factor])\r\n",
    "\r\n",
    "u0 = [ x => 1.0, y=> 1.0]\r\n",
    "\r\n",
    "params = [ a => 1.0, b => 100.0, penalty_factor => 10^6]\r\n",
    "\r\n",
    "prob = OptimizationProblem(sys,u0, params , grad=true, hess=false)\r\n",
    "\r\n",
    "callback = function (p,l)\r\n",
    "    println(\"Objective function value =  $l\")\r\n",
    "    return false\r\n",
    "end\r\n",
    "\r\n",
    "#  Broyden, Fletcher, Golfarb, Shanno (BFGS) method will be used\r\n",
    "\r\n",
    "result = solve(prob, BFGS(),x_abstol = 1e-12, \r\n",
    "                   f_abstol = 1e-12, g_abstol = 1e-12, cb = callback, \r\n",
    "                    show_every = 5, time_limit = 100 , iterations=100)\r\n",
    "\r\n",
    "#  Determine error in equality constraint\r\n",
    "\r\n",
    "error1 = result.minimizer[1]*result.minimizer[2] - 2.0\r\n",
    "\r\n",
    "println(\" \")\r\n",
    "println(\"Final value of objective function = \", result.minimum)\r\n",
    "println(\" \")\r\n",
    "println(\"Final error in eq. constraint = \", error1)\r\n",
    "println(\" \")\r\n",
    "println(\"Final value for x = \", result.minimizer[1])\r\n",
    "println(\" \")\r\n",
    "println(\"Final value for y = \", result.minimizer[2])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Objective function value =  1.0e6\n",
      "Objective function value =  33.64465731870688\n",
      "Objective function value =  4.973376250606183\n",
      "Objective function value =  0.08295360608528507\n",
      "Objective function value =  0.06751169397671551\n",
      " \n",
      "Final value of objective function = 0.06751169397671551\n",
      " \n",
      "Final error in eq. constraint = -5.4549692318772713e-8\n",
      " \n",
      "Final value for x = 1.2597392323717043\n",
      " \n",
      "Final value for y = 1.5876301174528942\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "#  Example problem 6 where the Rosenbrock function\r\n",
    "#  is optimized.  Example problem 2 will be repeated \r\n",
    "#  here except vector notation will be used. In particular\r\n",
    "#  the problem involves the vectors w and par where w[1] = x\r\n",
    "#  w[2] = y, par[1] = 1.0 and par[2] = 100.0\r\n",
    "\r\n",
    "#  Define the variables and parameters\r\n",
    "\r\n",
    "@variables w[1:2]  \r\n",
    "@parameters par[1:2]\r\n",
    "\r\n",
    "#  Define the objective function\r\n",
    "\r\n",
    "objective = (par[1] - w[1])^2 + par[2] * (w[2] - w[1]^2)^2\r\n",
    "\r\n",
    "#  Remainder of statements are similar to those above\r\n",
    "#  so most comments are eliminated below.\r\n",
    "\r\n",
    " @named  sys = OptimizationSystem(objective, [w[1],w[2]], [par[1],par[2]])\r\n",
    "\r\n",
    "w0 = [ w[1] => -1.0, w[2]=>-2.0]\r\n",
    "\r\n",
    "params = [par[1] => 1.0, par[2] => 100.0]\r\n",
    "\r\n",
    "prob = OptimizationProblem(sys, w0, params, grad=true, hess=false)\r\n",
    "\r\n",
    "callback = function (p,l)\r\n",
    "    println(\"Objective function value =  $l\")\r\n",
    "    return false\r\n",
    "end\r\n",
    "\r\n",
    "#  Broyden, Fletcher, Golfarb, Shanno (BFGS) method will be used\r\n",
    "\r\n",
    "result = solve(prob, BFGS(),x_abstol = 1e-12, \r\n",
    "                   f_abstol = 1e-12, g_abstol = 1e-12, cb = callback, \r\n",
    "                    show_every = 5, time_limit = 100 , iterations=100)\r\n",
    "\r\n",
    "println(\" \")\r\n",
    "println(\"Final value of objective function = \", result.minimum)\r\n",
    "println(\" \")\r\n",
    "println(\"Final value for x = \", result.minimizer[1])\r\n",
    "println(\" \")\r\n",
    "println(\"Final value for y = \", result.minimizer[2])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Objective function value =  904.0\n",
      "Objective function value =  2.741686784696232\n",
      "Objective function value =  0.7183143047436906\n",
      "Objective function value =  0.19150437378082646\n",
      "Objective function value =  0.010454489593595512\n",
      "Objective function value =  3.085381863762898e-5\n",
      " \n",
      "Final value of objective function = 1.5407439555097887e-30\n",
      " \n",
      "Final value for x = 0.9999999999999994\n",
      " \n",
      "Final value for y = 0.9999999999999988\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "#  Additional notes:\r\n",
    "\r\n",
    "#  1.  If there are no  parameters in the problem,\r\n",
    "#      then you can eliminate the @parameters statement.  But\r\n",
    "#      you still  need to include an empty vector (i.e., [])\r\n",
    "#      elsewhere where the parameters are supposed to \r\n",
    "#      appear, such as in the following statements:\r\n",
    "\r\n",
    "#   @named  sys = OptimizationSystem(objective, [x,y], [])\r\n",
    "#   prob = OptimizationProblem(sys,u0,[],grad=true,hess=false)\r\n",
    "\r\n",
    "#  2.  If you want to solve a system of algebraic equations\r\n",
    "#      such as:\r\n",
    "\r\n",
    "#             f(x,y) = 0   and g(x,y) = 0\r\n",
    "\r\n",
    "#      you can reformulate the above problem into the\r\n",
    "#      equivalent optimization problem:\r\n",
    "\r\n",
    "#           minimize:    (f(x,y))^2 + (g(x,y))^2\r\n",
    "\r\n",
    "#      The above optimzation problem can be solved as shown\r\n",
    "#      by the examples above.\r\n",
    "\r\n",
    "# 3.   The penalty method can be extended to the case of an\r\n",
    "#      inequality constraint.  For example, the following\r\n",
    "#      problem:\r\n",
    "\r\n",
    "#           minimize  g(x,y) \r\n",
    "#           subject to f(x,y) l.t.e 0.0\r\n",
    "\r\n",
    "#      (where l.t.e. means \"less than or equal to\") is equivalent to\r\n",
    "\r\n",
    "#         minimize  g(x,y) + penalty_factor * (min(0,f(x,y)))^2\r\n",
    "\r\n",
    "#      where the output of the min function is the lower of the two input arguments.\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia nteract 1.6.2",
   "language": "julia",
   "name": "julia-nteract-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "name": "julia",
   "mimetype": "application/julia",
   "version": "1.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}