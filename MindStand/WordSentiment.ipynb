{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json; import os; import pandas as pd; import spacy; import numpy as np\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Functions\n",
    " Vader Setiment\\\n",
    " Spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentSet = []\n",
    "def sentiment_scores(sentence):\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "    print(\"Overall sentiment dictionary is : \", sentiment_dict)\n",
    "    sentimentSet.append(sentiment_dict)\n",
    "    \n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jason file manipulation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting jason files in directory \n",
    "folders = os.listdir(\"edhrec Slack export Sep 4 2016 - Oct 23 2019\"); folderSize = (len(folders)); folderNames = [0]*folderSize\n",
    "ii = 0\n",
    "\n",
    "### Ignoring json files in folder (channels.json, integration_ logs.json, users.json)\n",
    "for count in range(len(folderNames)):\n",
    "\n",
    "    folderNames[ii] = folders[ii]   \n",
    "    ii += 1\n",
    "\n",
    "    if folderNames[ii-1] == \"channels.json\":\n",
    "        folderNames[ii-1] = 0\n",
    "\n",
    "    \n",
    "    if folderNames[ii-1] == \"integration_logs.json\":\n",
    "        folderNames[ii-1] = 0\n",
    "    \n",
    "    if folderNames[ii-1] == \"users.json\":\n",
    "        folderNames[ii-1] = 0\n",
    "###\n",
    "\n",
    "### Removing placed zeros             \n",
    "try:\n",
    "    while True:\n",
    "        folderNames.remove(0)\n",
    "except ValueError:\n",
    "    pass \n",
    "###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jason files to Python dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileList = []; folderList = []; folderPath = [0]*len(folderNames); mainPath = []; slackContent = []; all_possible_keys = set(); channelsDict = {'Channel':[]}\n",
    "\n",
    "jj = 0; ii = 0\n",
    "\n",
    "### Conversion of json files to python dictionaries and collection of key value pairs\n",
    "for Paths in folderNames:\n",
    "    \n",
    "    mainPath1 = 'C:/Users/solid/Documents/Scripts/Code/'\n",
    "    mainPath2 = 'MindStand/edhrec Slack export Sep 4 2016 - Oct 23 2019/'\n",
    "    folderPath[ii] = folderNames[ii]\n",
    "    folderList.append(os.path.join(mainPath1,mainPath2,folderPath[ii]))\n",
    "    fileIter = os.listdir(folderList[ii])\n",
    "    \n",
    "    for d in range(len(fileIter)):\n",
    "        fileList.append(fileIter[d])  \n",
    "        mainPath.append(os.path.join(folderList[ii],fileList[d]))\n",
    "        mainPath[jj] = mainPath[d].replace('\\\\','/')\n",
    "        with open(mainPath[ii], encoding=\"utf8\") as f:\n",
    "            data = json.load(f)\n",
    "            slackContent.append(data)\n",
    "            for d in data:\n",
    "                channelsDict['Channel'].append(Paths)\n",
    "                for k in d.keys():\n",
    "                    all_possible_keys.add(k)\n",
    "\n",
    "        jj += 1\n",
    "    ii += 1\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creation of dataframe based on a key: [list of values] organization\n",
    "main_data = {}\n",
    "for stuff in slackContent:\n",
    "    for p in stuff:\n",
    "        for field in list(all_possible_keys):\n",
    "            if field not in main_data:\n",
    "                main_data[field] = []\n",
    "            if field in p:\n",
    "                main_data[field].append(p[field])\n",
    "            else:\n",
    "                main_data[field].append(None)\n",
    "dataframe = pd.DataFrame.from_dict(main_data)\n",
    "df = dataframe[['text','thread_ts','user']]\n",
    "channelDataFrame = pd.DataFrame.from_dict(channelsDict)\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Iterating through dataframe and applying spacy\n",
    "dataStart = 2000\n",
    "dataEnd =  2100\n",
    "dataSpan = range(0,len(df),1)\n",
    "test_nlp = [0]*len(dataSpan)\n",
    "ii = 0\n",
    "for row in dataSpan:\n",
    "    test_nlp[ii] = nlp(df.text[row])\n",
    "    ii += 1 \n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of Noun, Verb, and Adjective sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordDataList = []\n",
    "# DataFrames = pd.DataFrame()\n",
    "ii = 0\n",
    "for row in test_nlp:\n",
    "    sentence = [row.text]\n",
    "    noun = [token.text for token in test_nlp[ii] if token.pos_ == \"NOUN\"]\n",
    "    Verb = [token.text for token in test_nlp[ii] if token.pos_ == \"VERB\"]\n",
    "    Adj = [token.text for token in test_nlp[ii] if token.pos_ == \"ADJ\"]\n",
    "    pt1 = sentence\n",
    "    pt2 = noun\n",
    "    pt1_pt2 = sentence,noun\n",
    "    wordDataList.append([pt1_pt2])\n",
    "    iterDataFrame = pd.DataFrame(wordDataList[0], columns=['Sentence','Nouns'])\n",
    "    # wordDataFrame = DataFrames.append(iterDataFrame)\n",
    "    wordDataFrame = pd.DataFrame().append(iterDataFrame)\n",
    "    \n",
    "    ii+=1\n",
    "# wordDataFrame = pd.DataFrame(wordDataList[-1],columns=['sentence','Noun'])\n",
    "# wordDataFrame = pd.DataFrame({'sentence':pt1,'Noun':pt2})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordDataList = []\n",
    "iterDataFrame = [0]*len(test_nlp)\n",
    "# DataFrames = pd.DataFrame()\n",
    "ii = 0\n",
    "for row in test_nlp:\n",
    "    Sentence = [row.text]\n",
    "    Noun = [token.text for token in test_nlp[ii] if token.pos_ == \"NOUN\"]\n",
    "    Verb = [token.text for token in test_nlp[ii] if token.pos_ == \"VERB\"]\n",
    "    Adj = [token.text for token in test_nlp[ii] if token.pos_ == \"ADJ\"]\n",
    "    pt1 = sentence\n",
    "    pt2 = Noun\n",
    "    pt3 = Verb\n",
    "    pt4 = Adj\n",
    "    pts = Sentence,Noun,Verb,Adj\n",
    "    wordDataList.append(pts)\n",
    "    ii+=1\n",
    "\n",
    "DataFrame = pd.DataFrame(wordDataList,columns=['Sentence','Noun','Verb','Adjective'])\n",
    "wordDataFrame = DataFrame.join(channelDataFrame).join(dataframe['user'])\n",
    "wordDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### List items as strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_alt_list(list_):\n",
    "    list_ = list_.replace(', ', '\",\"')\n",
    "    list_ = list_.replace('[', '[\"')\n",
    "    list_ = list_.replace(']', '\"]')\n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meme= wordDataFrame\n",
    "meme = meme.explode('Sentence')\n",
    "meme['Sentence'] = meme['Sentence'].str.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305151\n",
      "919\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Noun</th>\n",
       "      <th>Verb</th>\n",
       "      <th>Adjective</th>\n",
       "      <th>Channel</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Drive to Work #12, #436 and #437 all cover GDS...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Drive, Work, cover]</td>\n",
       "      <td>[]</td>\n",
       "      <td>amateurdesignerhour</td>\n",
       "      <td>U3QMCLQQG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Here's one of the articles</td>\n",
       "      <td>[articles]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>amateurdesignerhour</td>\n",
       "      <td>U3QMCLQQG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>This guy failed the test for GDS2 by one quest...</td>\n",
       "      <td>[guy, test, question, answers]</td>\n",
       "      <td>[failed]</td>\n",
       "      <td>[]</td>\n",
       "      <td>amateurdesignerhour</td>\n",
       "      <td>U3QMCLQQG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Do you have any ideas for themes your stuff wi...</td>\n",
       "      <td>[ideas, themes, stuff]</td>\n",
       "      <td>[have, explore]</td>\n",
       "      <td>[]</td>\n",
       "      <td>aprilfools</td>\n",
       "      <td>U3QMCLQQG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>I'm very curious about exploring where colors ...</td>\n",
       "      <td>[colors, talks, color, wheel, time, colors, co...</td>\n",
       "      <td>['m, exploring, go, changing, change, remain, ...</td>\n",
       "      <td>[curious, mechanical, future]</td>\n",
       "      <td>aprilfools</td>\n",
       "      <td>U3L7A68JC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233305</th>\n",
       "      <td>I guess it could just be solved by removing al...</td>\n",
       "      <td>[counters, creatures, memory, issues]</td>\n",
       "      <td>[guess, solved, removing, leaves, eliminates]</td>\n",
       "      <td>[]</td>\n",
       "      <td>shittalk</td>\n",
       "      <td>U3FV90TCZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233306</th>\n",
       "      <td>[Insert 1/1 counter text]\\n\\nCreatures are 0/0...</td>\n",
       "      <td>[counter, text, Creatures, leaves, counters, c...</td>\n",
       "      <td>[remove]</td>\n",
       "      <td>[]</td>\n",
       "      <td>shittalk</td>\n",
       "      <td>U3FV90TCZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233307</th>\n",
       "      <td>Gives it some added tension/ risk-reward with ...</td>\n",
       "      <td>[risk, reward, P, T, self, plague, wind]</td>\n",
       "      <td>[Gives, added, doubles, remove]</td>\n",
       "      <td>[]</td>\n",
       "      <td>shittalk</td>\n",
       "      <td>U3FV90TCZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233308</th>\n",
       "      <td>Do you really think there are memory issues, t...</td>\n",
       "      <td>[memory, issues, version, fun, minigame, encha...</td>\n",
       "      <td>[think, made, figured, be, try, remove, double]</td>\n",
       "      <td>[legendary, entire]</td>\n",
       "      <td>shittalk</td>\n",
       "      <td>UEF135G05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233309</th>\n",
       "      <td>Well, doubling the board’s P/T by removing it ...</td>\n",
       "      <td>[board, P, part, card, ideas, counters, resour...</td>\n",
       "      <td>[doubling, removing, want, work, throwing, use...</td>\n",
       "      <td>[original, messy, particular, first]</td>\n",
       "      <td>shittalk</td>\n",
       "      <td>U3FV90TCZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>919 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Sentence  \\\n",
       "6       Drive to Work #12, #436 and #437 all cover GDS...   \n",
       "9                              Here's one of the articles   \n",
       "11      This guy failed the test for GDS2 by one quest...   \n",
       "585     Do you have any ideas for themes your stuff wi...   \n",
       "586     I'm very curious about exploring where colors ...   \n",
       "...                                                   ...   \n",
       "233305  I guess it could just be solved by removing al...   \n",
       "233306  [Insert 1/1 counter text]\\n\\nCreatures are 0/0...   \n",
       "233307  Gives it some added tension/ risk-reward with ...   \n",
       "233308  Do you really think there are memory issues, t...   \n",
       "233309  Well, doubling the board’s P/T by removing it ...   \n",
       "\n",
       "                                                     Noun  \\\n",
       "6                                                      []   \n",
       "9                                              [articles]   \n",
       "11                         [guy, test, question, answers]   \n",
       "585                                [ideas, themes, stuff]   \n",
       "586     [colors, talks, color, wheel, time, colors, co...   \n",
       "...                                                   ...   \n",
       "233305              [counters, creatures, memory, issues]   \n",
       "233306  [counter, text, Creatures, leaves, counters, c...   \n",
       "233307           [risk, reward, P, T, self, plague, wind]   \n",
       "233308  [memory, issues, version, fun, minigame, encha...   \n",
       "233309  [board, P, part, card, ideas, counters, resour...   \n",
       "\n",
       "                                                     Verb  \\\n",
       "6                                    [Drive, Work, cover]   \n",
       "9                                                      []   \n",
       "11                                               [failed]   \n",
       "585                                       [have, explore]   \n",
       "586     ['m, exploring, go, changing, change, remain, ...   \n",
       "...                                                   ...   \n",
       "233305      [guess, solved, removing, leaves, eliminates]   \n",
       "233306                                           [remove]   \n",
       "233307                    [Gives, added, doubles, remove]   \n",
       "233308    [think, made, figured, be, try, remove, double]   \n",
       "233309  [doubling, removing, want, work, throwing, use...   \n",
       "\n",
       "                                   Adjective              Channel       user  \n",
       "6                                         []  amateurdesignerhour  U3QMCLQQG  \n",
       "9                                         []  amateurdesignerhour  U3QMCLQQG  \n",
       "11                                        []  amateurdesignerhour  U3QMCLQQG  \n",
       "585                                       []           aprilfools  U3QMCLQQG  \n",
       "586            [curious, mechanical, future]           aprilfools  U3L7A68JC  \n",
       "...                                      ...                  ...        ...  \n",
       "233305                                    []             shittalk  U3FV90TCZ  \n",
       "233306                                    []             shittalk  U3FV90TCZ  \n",
       "233307                                    []             shittalk  U3FV90TCZ  \n",
       "233308                   [legendary, entire]             shittalk  UEF135G05  \n",
       "233309  [original, messy, particular, first]             shittalk  U3FV90TCZ  \n",
       "\n",
       "[919 rows x 6 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meme['Sentence'] = meme.loc[meme['Sentence'].str.contains(r'https')==False]\n",
    "meme = meme.loc[meme['Sentence'].str.contains(r'@')==False]\n",
    "meme = meme.loc[meme['Sentence'].str.contains(r'::')==False]\n",
    "meme = meme.loc[meme['Sentence'].str.contains(r'\\\\')==False]\n",
    "meme = meme.loc[meme['Sentence'].str.contains(r'\\+')==False]\n",
    "# meme = meme.dropna(subset = [\"Sentence\"],inplace=True)\n",
    "# print(len(wordDataFrame))\n",
    "# print(len(meme))\n",
    "# for index, row in meme.iterrows():\n",
    "#     if row.any() == 'NaN':\n",
    "#         meme.drop(index,inplace=True)\n",
    "# print(len(meme['Sentence']))\n",
    "# print(len(meme['Noun']))\n",
    "meme.dropna(inplace=True)\n",
    "meme['Sentence'].replace('',np.nan,inplace=True)\n",
    "meme.dropna(subset=['Sentence'],inplace=True)\n",
    "print(len(wordDataFrame))\n",
    "print(len(meme))\n",
    "meme.drop_duplicates(subset=[\"Sentence\"],inplace=True)\n",
    "meme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Noun</th>\n",
       "      <th>Verb</th>\n",
       "      <th>Adjective</th>\n",
       "      <th>Channel</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;@U3QMCLQQG&gt; has joined the channel</td>\n",
       "      <td>[channel]</td>\n",
       "      <td>[joined]</td>\n",
       "      <td>[]</td>\n",
       "      <td>amateurdesignerhour</td>\n",
       "      <td>U3QMCLQQG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;@U3QMCLQQG&gt; set the channel purpose: Discuss,...</td>\n",
       "      <td>[channel, purpose, study, practice]</td>\n",
       "      <td>[set, prepare]</td>\n",
       "      <td>[]</td>\n",
       "      <td>amateurdesignerhour</td>\n",
       "      <td>U3QMCLQQG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;@U3QMCLQQG&gt; pinned their File  to this channel.</td>\n",
       "      <td>[channel]</td>\n",
       "      <td>[pinned]</td>\n",
       "      <td>[]</td>\n",
       "      <td>amateurdesignerhour</td>\n",
       "      <td>U3QMCLQQG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;@U3MTAQBE1&gt; has joined the channel</td>\n",
       "      <td>[channel]</td>\n",
       "      <td>[joined]</td>\n",
       "      <td>[]</td>\n",
       "      <td>amateurdesignerhour</td>\n",
       "      <td>U3MTAQBE1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;@U3MTJRAQL&gt; has joined the channel</td>\n",
       "      <td>[channel]</td>\n",
       "      <td>[joined]</td>\n",
       "      <td>[]</td>\n",
       "      <td>amateurdesignerhour</td>\n",
       "      <td>U3MTJRAQL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305146</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[https://magic.wizards.com/en/articles/archive...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>youtube-monitor</td>\n",
       "      <td>U3QMCLQQG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305147</th>\n",
       "      <td>This guy failed the test for GDS2 by one quest...</td>\n",
       "      <td>[guy, test, question, answers]</td>\n",
       "      <td>[failed]</td>\n",
       "      <td>[]</td>\n",
       "      <td>youtube-monitor</td>\n",
       "      <td>U3QMCLQQG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305148</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>youtube-monitor</td>\n",
       "      <td>U3QMCLQQG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305149</th>\n",
       "      <td>&lt;@U3FV90TCZ&gt; has joined the channel</td>\n",
       "      <td>[channel]</td>\n",
       "      <td>[joined]</td>\n",
       "      <td>[]</td>\n",
       "      <td>youtube-monitor</td>\n",
       "      <td>U3FV90TCZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305150</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>youtube-monitor</td>\n",
       "      <td>U3RJ9VDRT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292842 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Sentence  \\\n",
       "0                     <@U3QMCLQQG> has joined the channel   \n",
       "1       <@U3QMCLQQG> set the channel purpose: Discuss,...   \n",
       "3        <@U3QMCLQQG> pinned their File  to this channel.   \n",
       "4                     <@U3MTAQBE1> has joined the channel   \n",
       "5                     <@U3MTJRAQL> has joined the channel   \n",
       "...                                                   ...   \n",
       "305146                                                NaN   \n",
       "305147  This guy failed the test for GDS2 by one quest...   \n",
       "305148                                                NaN   \n",
       "305149                <@U3FV90TCZ> has joined the channel   \n",
       "305150                                                NaN   \n",
       "\n",
       "                                                     Noun            Verb  \\\n",
       "0                                               [channel]        [joined]   \n",
       "1                     [channel, purpose, study, practice]  [set, prepare]   \n",
       "3                                               [channel]        [pinned]   \n",
       "4                                               [channel]        [joined]   \n",
       "5                                               [channel]        [joined]   \n",
       "...                                                   ...             ...   \n",
       "305146  [https://magic.wizards.com/en/articles/archive...              []   \n",
       "305147                     [guy, test, question, answers]        [failed]   \n",
       "305148                                                 []              []   \n",
       "305149                                          [channel]        [joined]   \n",
       "305150                                                 []              []   \n",
       "\n",
       "       Adjective              Channel       user  \n",
       "0             []  amateurdesignerhour  U3QMCLQQG  \n",
       "1             []  amateurdesignerhour  U3QMCLQQG  \n",
       "3             []  amateurdesignerhour  U3QMCLQQG  \n",
       "4             []  amateurdesignerhour  U3MTAQBE1  \n",
       "5             []  amateurdesignerhour  U3MTJRAQL  \n",
       "...          ...                  ...        ...  \n",
       "305146        []      youtube-monitor  U3QMCLQQG  \n",
       "305147        []      youtube-monitor  U3QMCLQQG  \n",
       "305148        []      youtube-monitor  U3QMCLQQG  \n",
       "305149        []      youtube-monitor  U3FV90TCZ  \n",
       "305150        []      youtube-monitor  U3RJ9VDRT  \n",
       "\n",
       "[292842 rows x 6 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meme[meme['Sentence'].astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialchara = wordDataFrame.loc[wordDataFrame['Sentence'].str.contains(r'@')==False]\n",
    "specialchara = specialchara.loc[specialchara['Sentence'].str.contains(r'https')==False]\n",
    "specialchara = specialchara.loc[specialchara['Sentence'].str.contains(r'::')==False]\n",
    "specialchara = specialchara.loc[specialchara['Sentence'].str.contains(r'\\\\')==False]\n",
    "wordDataFrame = specialchara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meme = wordDataFrame.drop_duplicates(subset=\"Sentence\",keep=False,inplace=True)\n",
    "wordDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordDataFrame.loc[wordDataFrame['Noun']=='guy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordDataFrame['Sentence'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4e6d9786dc1ab3736f85b775378532d8fe18afb1540be17e5c41974a5249fde"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
